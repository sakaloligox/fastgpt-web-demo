# FastGPT Web Demo

This is a multimodal web demo that allows users to interact with a large language model (LLM) via image and voice input. It leverages the [FastGPT](https://github.com/labring/FastGPT) platform for knowledge base construction and API access, and is deployed to the public internet via Render.

## ğŸ”§ Project Overview

- ğŸ’¬ **LLM Backend:** Built with FastGPT, supporting knowledge base Q&A and multimodal inputs (text + image).
- ğŸŒ **Frontend:** A lightweight HTML/JavaScript interface developed in VS Code, featuring:
  - Real-time webcam capture (defaults to rear camera on mobile)
  - Voice input (speech recognition with language selection)
  - Image preview before sending
  - Speech synthesis playback of the model's response
- â˜ï¸ **Deployment:** Publicly accessible via [Render](https://render.com/), making the application easy to use from any device.

## ğŸ“¦ Project Structure

```
fastgpt-web-demo/
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Main HTML UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ script.js         # Frontend logic (camera, speech, fetch)
â”œâ”€â”€ .env                  # Environment variables for API key and URL
â”œâ”€â”€ .render.yaml          # Render deployment configuration
â”œâ”€â”€ server.py             # Flask backend handling API proxy
â””â”€â”€ README.md             # Project description (this file)
```

## ğŸ§ª Local Development

1. **Install dependencies**:
   ```bash
   pip install flask flask-cors python-dotenv requests
   ```

2. **Set up environment variables**:
   Create a `.env` file:
   ```
   FASTGPT_API_KEY=your-fastgpt-api-key
   FASTGPT_URL=https://api.fastgpt.in/api/v1/chat/completions
   ```

3. **Start the server**:
   ```bash
   python server.py
   ```

4. **Access via browser**:
   ```
   http://localhost:5000
   ```

## ğŸŒ Deployment via Render

1. Push your code to GitHub.
2. Create a **Web Service** on [Render](https://render.com/).
3. Set `Start Command` to:
   ```bash
   python server.py
   ```
4. Add environment variables (`FASTGPT_API_KEY`, `FASTGPT_URL`) via the Render dashboard.

> âš ï¸ Do **not** hardcode your API key into the source code. Use environment variables for security.

## âœ¨ Features

- ğŸ“· Image capture via webcam (auto rear-facing on mobile)
- ğŸ™ï¸ Speech recognition in Chinese, English, or Japanese
- ğŸ–¼ï¸ Image preview before sending to GPT
- ğŸ§  Multimodal GPT response with knowledge base integration
- ğŸ”Š Spoken feedback of GPT's response (auto language detection)
- ğŸ” Toggle buttons for voice input and speech playback

## ğŸ“Œ TODO / Ideas

- Add file upload support
- Add GPT function calling or tool support
- Display conversation history
- Dark mode UI

## ğŸ“„ License

MIT License

---

**Made with â¤ï¸ using FastGPT + Flask + Render**
